{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"name":"train_model.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"XoQpd6nUzKi8"},"source":["# Collision Avoidance - Train Model\n","\n","Welcome to this host side Jupyter Notebook!  This should look familiar if you ran through the notebooks that run on the robot.  In this notebook we'll train our image classifier to detect two classes\n","``free`` and ``blocked``, which we'll use for avoiding collisions.  For this, we'll use a popular deep learning library *PyTorch*"]},{"cell_type":"code","metadata":{"id":"C-KXQ5xnzKjJ","executionInfo":{"status":"ok","timestamp":1611317145472,"user_tz":-60,"elapsed":1924718,"user":{"displayName":"Carlo Cena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0f3a0eH9ojDaNw5OS4vAEjBjEgOMrbr5i7JdQ8Q=s64","userId":"14201859508342393884"}}},"source":["import torch\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.models as models\n","import torchvision.transforms as transforms"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ZrWM-ahzbkj","executionInfo":{"status":"ok","timestamp":1611317145475,"user_tz":-60,"elapsed":1924708,"user":{"displayName":"Carlo Cena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0f3a0eH9ojDaNw5OS4vAEjBjEgOMrbr5i7JdQ8Q=s64","userId":"14201859508342393884"}},"outputId":"a13339b6-ba11-4c70-8b45-432d9a57f879"},"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive/MyDrive/tello/"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n","/gdrive/MyDrive/tello\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pWnFu4P4zKjO"},"source":["### Create dataset instance"]},{"cell_type":"markdown","metadata":{"id":"rZtZIoPpzKjQ"},"source":["Now we use the ``ImageFolder`` dataset class available with the ``torchvision.datasets`` package.  We attach transforms from the ``torchvision.transforms`` package to prepare the data for training.  "]},{"cell_type":"code","metadata":{"id":"Dl-U93RAzKjQ","executionInfo":{"status":"ok","timestamp":1611317145478,"user_tz":-60,"elapsed":1924705,"user":{"displayName":"Carlo Cena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0f3a0eH9ojDaNw5OS4vAEjBjEgOMrbr5i7JdQ8Q=s64","userId":"14201859508342393884"}}},"source":["dataset = datasets.ImageFolder(\n","    'collision_avoidance',\n","    transforms.Compose([\n","        transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ])\n",")"],"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tALaJvRfzKjR"},"source":["### Split dataset into train and test sets"]},{"cell_type":"markdown","metadata":{"id":"toVyk-SRzKjS"},"source":["Next, we split the dataset into *training* and *test* sets.  The test set will be used to verify the accuracy of the model we train."]},{"cell_type":"code","metadata":{"id":"AOCCKR76zKjT","executionInfo":{"status":"ok","timestamp":1611317145479,"user_tz":-60,"elapsed":1924703,"user":{"displayName":"Carlo Cena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0f3a0eH9ojDaNw5OS4vAEjBjEgOMrbr5i7JdQ8Q=s64","userId":"14201859508342393884"}}},"source":["train_len = int(len(dataset)*0.5)\n","valid_len = len(dataset) - train_len\n","train_dataset, valid_dataset = torch.utils.data.random_split(dataset, [train_len, valid_len])"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t-9FmoDKzKjT","executionInfo":{"status":"ok","timestamp":1611317145480,"user_tz":-60,"elapsed":1924697,"user":{"displayName":"Carlo Cena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0f3a0eH9ojDaNw5OS4vAEjBjEgOMrbr5i7JdQ8Q=s64","userId":"14201859508342393884"}},"outputId":"1e78ce43-f42f-4add-9c2f-609eeca12d3b"},"source":["print(len(train_dataset))\n","print(len(valid_dataset))"],"execution_count":33,"outputs":[{"output_type":"stream","text":["779\n","779\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IW7mTR9ZzKjW"},"source":["### Create data loaders to load data in batches"]},{"cell_type":"markdown","metadata":{"id":"zhyRhbWdzKjX"},"source":["We'll create two ``DataLoader`` instances, which provide utilities for shuffling data, producing *batches* of images, and loading the samples in parallel with multiple workers."]},{"cell_type":"code","metadata":{"id":"tmcNsm1EzKjc","executionInfo":{"status":"ok","timestamp":1611317145482,"user_tz":-60,"elapsed":1924695,"user":{"displayName":"Carlo Cena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0f3a0eH9ojDaNw5OS4vAEjBjEgOMrbr5i7JdQ8Q=s64","userId":"14201859508342393884"}}},"source":["train_loader = torch.utils.data.DataLoader(\n","    train_dataset,\n","    batch_size=64,\n","    shuffle=True,\n","    num_workers=0,\n","    pin_memory=True\n",")\n","\n","valid_loader = torch.utils.data.DataLoader(\n","    valid_dataset,\n","    batch_size=64,\n","    shuffle=True,\n","    num_workers=0,\n","    pin_memory=True\n",")"],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9YUDCr-ZzKje"},"source":["### Define the neural network\n","\n","Now, we define the neural network we'll be training.  The *torchvision* package provides a collection of pre-trained models that we can use.\n","\n","In a process called *transfer learning*, we can repurpose a pre-trained model (trained on millions of images) for a new task that has possibly much less data available.\n","\n","Important features that were learned in the original training of the pre-trained model are re-usable for the new task.  We'll use the ``alexnet`` model."]},{"cell_type":"code","metadata":{"id":"gZO9wxbkzKje","executionInfo":{"status":"ok","timestamp":1611317145851,"user_tz":-60,"elapsed":1925060,"user":{"displayName":"Carlo Cena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0f3a0eH9ojDaNw5OS4vAEjBjEgOMrbr5i7JdQ8Q=s64","userId":"14201859508342393884"}}},"source":["model = models.alexnet(pretrained=True)"],"execution_count":35,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0wn3-q0szKjf"},"source":["The ``alexnet`` model was originally trained for a dataset that had 1000 class labels, but our dataset only has two class labels!  We'll replace\n","the final layer with a new, untrained layer that has only two outputs.  "]},{"cell_type":"code","metadata":{"id":"sAG69jImzKjg","executionInfo":{"status":"ok","timestamp":1611317145855,"user_tz":-60,"elapsed":1925061,"user":{"displayName":"Carlo Cena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0f3a0eH9ojDaNw5OS4vAEjBjEgOMrbr5i7JdQ8Q=s64","userId":"14201859508342393884"}}},"source":["model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 2)"],"execution_count":36,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hj8dHzT4zKjh"},"source":["Finally, we transfer our model for execution on the GPU"]},{"cell_type":"code","metadata":{"id":"1Nu6npw4zKjh","executionInfo":{"status":"ok","timestamp":1611317146201,"user_tz":-60,"elapsed":1925404,"user":{"displayName":"Carlo Cena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0f3a0eH9ojDaNw5OS4vAEjBjEgOMrbr5i7JdQ8Q=s64","userId":"14201859508342393884"}}},"source":["device = torch.device('cuda')\n","model = model.to(device)"],"execution_count":37,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uB4h1nqTzKjh"},"source":["### Train the neural network\n","\n","Using the code below we will train the neural network for 30 epochs, saving the best performing model after each epoch.\n","\n","> An epoch is a full run through our data."]},{"cell_type":"code","metadata":{"id":"imLDize7zKjh"},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","cont = 0\n","for images, labels in iter(train_loader):\n","    if cont >= 50:\n","        break\n","    cont += 1\n","    img = np.reshape(images[0], (224, 224, 3))\n","    plt.imshow(img)\n","    plt.show()\n","    print(labels[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"c69Qns92zKjk","outputId":"fbda93fb-4108-4e50-9142-4e5b50eee7af"},"source":["NUM_EPOCHS = 30\n","BEST_MODEL_PATH = 'best_model.pth'\n","best_f1 = 0.0\n","\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","for epoch in range(NUM_EPOCHS):\n","    \n","    for images, labels in iter(train_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = F.cross_entropy(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","    \n","    valid_fp_count = 0.0\n","    valid_fn_count = 0.0\n","    valid_tp_count = 0.0\n","    valid_tn_count = 0.0\n","    valid_accuracy = 0.0\n","    for images, labels in iter(valid_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        if len(labels[labels==0]) > 0:\n","            valid_fn_count += float(torch.sum(labels[labels==0] != outputs[labels==0].argmax(1)))\n","            valid_tp_count += float(torch.sum(labels[labels==0] == outputs[labels==0].argmax(1)))\n","        if len(labels[labels==1]) > 0:\n","            valid_fp_count += float(torch.sum(labels[labels==1] != outputs[labels==1].argmax(1)))\n","            valid_tn_count += float(torch.sum(labels[labels==1] == outputs[labels==1].argmax(1)))\n","        valid_accuracy += float(torch.sum(torch.abs(labels - outputs.argmax(1))))\n","    precision = valid_tp_count/(valid_tp_count + valid_fp_count)\n","    recall = valid_tp_count/(valid_tp_count + valid_fn_count)\n","    valid_accuracy /= len(valid_loader)\n","    \n","    print(\"Precision \", precision)\n","    print(\"Recall \", recall)\n","    print(\"fp \", valid_fp_count)\n","    print(\"fn \", valid_fn_count)\n","    print(\"tp \", valid_tp_count)\n","    print(\"tn \", valid_tn_count)\n","    print(\"Accuracy \", valid_accuracy)\n","    \n","    valid_f1 = 2*precision*recall/(precision+recall)\n","    print('%d: %f' % (epoch, valid_f1))\n","    if valid_f1 > best_f1:\n","        torch.save(model.state_dict(), BEST_MODEL_PATH)\n","        best_f1 = valid_f1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Precision  0.874251497005988\n","Recall  0.44242424242424244\n","fp  21.0\n","fn  184.0\n","tp  146.0\n","tn  428.0\n","Accuracy  15.76923076923077\n","0: 0.587525\n","Precision  0.9074074074074074\n","Recall  0.593939393939394\n","fp  20.0\n","fn  134.0\n","tp  196.0\n","tn  429.0\n","Accuracy  11.846153846153847\n","1: 0.717949\n","Precision  0.8719723183391004\n","Recall  0.7636363636363637\n","fp  37.0\n","fn  78.0\n","tp  252.0\n","tn  412.0\n","Accuracy  8.846153846153847\n","2: 0.814216\n","Precision  0.8544303797468354\n","Recall  0.8181818181818182\n","fp  46.0\n","fn  60.0\n","tp  270.0\n","tn  403.0\n","Accuracy  8.153846153846153\n","3: 0.835913\n","Precision  0.8033707865168539\n","Recall  0.8666666666666667\n","fp  70.0\n","fn  44.0\n","tp  286.0\n","tn  379.0\n","Accuracy  8.76923076923077\n","4: 0.833819\n","Precision  0.8258426966292135\n","Recall  0.8909090909090909\n","fp  62.0\n","fn  36.0\n","tp  294.0\n","tn  387.0\n","Accuracy  7.538461538461538\n","5: 0.857143\n","Precision  0.9154929577464789\n","Recall  0.7878787878787878\n","fp  24.0\n","fn  70.0\n","tp  260.0\n","tn  425.0\n","Accuracy  7.230769230769231\n","6: 0.846906\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vVZs_eLUzKjk"},"source":["Once that is finished, you should see a file ``best_model.pth`` in the Jupyter Lab file browser.  Select ``Right click`` -> ``Download`` to download the model to your workstation"]}]}