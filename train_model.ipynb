{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"name":"train_model.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"XoQpd6nUzKi8"},"source":["# Collision Avoidance - Train Model"]},{"cell_type":"code","metadata":{"id":"C-KXQ5xnzKjJ"},"source":["import torch\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.models as models\n","import torchvision.transforms as transforms"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ZrWM-ahzbkj"},"source":["#from google.colab import drive\n","#drive.mount('/gdrive')\n","#%cd /gdrive/MyDrive/tello/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pWnFu4P4zKjO"},"source":["### Create dataset instance"]},{"cell_type":"code","metadata":{"id":"Dl-U93RAzKjQ"},"source":["dataset = datasets.ImageFolder(\n","    'data',\n","    transforms.Compose([\n","        transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ])\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tALaJvRfzKjR"},"source":["### Split dataset into train and test sets"]},{"cell_type":"code","metadata":{"id":"AOCCKR76zKjT"},"source":["train_len = int(len(dataset)*0.5)\n","valid_len = len(dataset) - train_len\n","train_dataset, valid_dataset = torch.utils.data.random_split(dataset, [train_len, valid_len])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IW7mTR9ZzKjW"},"source":["### Create data loaders to load data in batches"]},{"cell_type":"code","metadata":{"id":"tmcNsm1EzKjc"},"source":["train_loader = torch.utils.data.DataLoader(\n","    train_dataset,\n","    batch_size=64,\n","    shuffle=True,\n","    num_workers=0,\n","    pin_memory=True\n",")\n","\n","valid_loader = torch.utils.data.DataLoader(\n","    valid_dataset,\n","    batch_size=64,\n","    shuffle=True,\n","    num_workers=0,\n","    pin_memory=True\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9YUDCr-ZzKje"},"source":["### Define the neural network"]},{"cell_type":"code","metadata":{"id":"gZO9wxbkzKje"},"source":["model = models.alexnet(pretrained=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sAG69jImzKjg"},"source":["model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Nu6npw4zKjh"},"source":["device = torch.device('cuda') # Change to cpu if no cuda available\n","model = model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uB4h1nqTzKjh"},"source":["### Train the neural network"]},{"cell_type":"code","metadata":{"id":"imLDize7zKjh"},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","cont = 0\n","for images, labels in iter(train_loader):\n","    if cont >= 10:\n","        break\n","    cont += 1\n","    img = np.reshape(images[0], (224, 224, 3))\n","    plt.imshow(img)\n","    plt.show()\n","    print(labels[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"c69Qns92zKjk"},"source":["NUM_EPOCHS = 30\n","BEST_MODEL_PATH = 'saved_models/best_model.pth'\n","best_f1 = 0.0\n","\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","for epoch in range(NUM_EPOCHS):\n","    \n","    for images, labels in iter(train_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = F.cross_entropy(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","    \n","    valid_fp_count = 0.0\n","    valid_fn_count = 0.0\n","    valid_tp_count = 0.0\n","    valid_tn_count = 0.0\n","    valid_accuracy = 0.0\n","    for images, labels in iter(valid_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        if len(labels[labels==0]) > 0:\n","            valid_fn_count += float(torch.sum(labels[labels==0] != outputs[labels==0].argmax(1)))\n","            valid_tp_count += float(torch.sum(labels[labels==0] == outputs[labels==0].argmax(1)))\n","        if len(labels[labels==1]) > 0:\n","            valid_fp_count += float(torch.sum(labels[labels==1] != outputs[labels==1].argmax(1)))\n","            valid_tn_count += float(torch.sum(labels[labels==1] == outputs[labels==1].argmax(1)))\n","        valid_accuracy += float(torch.sum(torch.abs(labels - outputs.argmax(1))))\n","    precision = valid_tp_count/(valid_tp_count + valid_fp_count)\n","    recall = valid_tp_count/(valid_tp_count + valid_fn_count)\n","    valid_accuracy /= len(valid_loader)\n","    \n","    print(\"Precision \", precision)\n","    print(\"Recall \", recall)\n","    print(\"fp \", valid_fp_count)\n","    print(\"fn \", valid_fn_count)\n","    print(\"tp \", valid_tp_count)\n","    print(\"tn \", valid_tn_count)\n","    print(\"Accuracy \", valid_accuracy)\n","    \n","    valid_f1 = 2*precision*recall/(precision+recall)\n","    print('%d: %f' % (epoch, valid_f1))\n","    if valid_f1 > best_f1:\n","        torch.save(model.state_dict(), BEST_MODEL_PATH)\n","        best_f1 = valid_f1"],"execution_count":null,"outputs":[]}]}